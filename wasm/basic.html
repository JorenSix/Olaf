<!DOCTYPE HTML>
<html>
<head>
	<title>Olaf audio fingerprinting WASM demo</title>
	<style>
		body {
			padding-left: 0;
			margin:0;
			padding-right: 0;
			font-family: sans-serif;
		}
	</style>
</head>
<body>

	<button onclick="startOrStopAudio()">Start or stop audio</button>

	<label  style="margin-top:1em;display: block;font-size: 100%">Match found: <input disabled type="checkbox" id="match_found"></input>&nbsp;&nbsp;Estimated reference time (s): <span style="font-family: monospace;" id="time">0.00</span></label>
	
	<textarea id="console_out" readonly style="margin-top:1em;display: block;width:98%;padding:0;height:10em;font-family: monospace;">Press the start button to begin audio fingerprinting.</textarea>

	<script>
		var audioContext = null;
		var microphoneStream = null;

		const found_checkbox = document.getElementById("match_found");
		const time = document.getElementById("time");
		var textarea = document.getElementById('console_out');

		var reference_query_time_delta = 0;

		function updateMatch(match_info){
			let found_match = match_info['query_time_start'];
			let match_time = match_info['time'];

			//report match or no match
			if(found_match){
				reference_query_time_delta = match_info['reference_time_start'] - match_info['query_time_start'];
				let estimated_playing_time = audioContext.currentTime + reference_query_time_delta;
				textarea.value +=  (match_time).toFixed(2)+ ": match found! Match count " + match_info['match_count'] + ", reference time: " +  (estimated_playing_time).toFixed(2) + "\n";
				console.log(match_info);
			}else{
				reference_query_time_delta = 0;
				textarea.value += (match_time).toFixed(2) + ": no match found \n";
			}
			textarea.scrollTop = textarea.scrollHeight;


			//state flipped from not matching to matching state
			if(found_match && !found_checkbox.checked){
				found_checkbox.checked = true;
				showEstimatedTime();
			}

			//state flipped from matching to not matching state
			if(!found_match && found_checkbox.checked){
				found_checkbox.checked = false;
				time.innerText = 0.0.toFixed(2);
			}

		}

		function showEstimatedTime(){
			if(reference_query_time_delta != 0){
				let estimated_playing_time = audioContext.currentTime + reference_query_time_delta;
				time.innerText = (estimated_playing_time).toFixed(2);
				requestAnimationFrame(showEstimatedTime);
			}
		}


		var audioContext = null;
		var microphoneStream = null;

		    
		function startOrStopAudio(){
		  if(audioContext == null){

		  	console.log("Starting audio stream");
		  	navigator.mediaDevices.getUserMedia({audio:  {sampleRate: 16000 },video: false}).then(stream => {

		        microphoneStream = stream;
		    		audioContext = new AudioContext();
		    		var microphone = audioContext.createMediaStreamSource(stream);

		        console.log(audioContext.sampleRate);

		        audioContext.audioWorklet.addModule('js/olaf_processor.js').then(() => {

		            // After the resolution of module loading, an AudioWorkletNode can be
		            // constructed.
		            let olafWorkletNode = new AudioWorkletNode(audioContext, 'olaf-processor', {
		            });
		            
		            microphone.connect(olafWorkletNode);
		            olafWorkletNode.connect(audioContext.destination);

		            olafWorkletNode.port.onmessage = (event) => {
		              let data = event.data;
		              data['time'] = audioContext.currentTime; 
		              updateMatch(data);
		            };
		        });

		    	}).catch(err => { alert("Microphone is required." + err);});

		  }else{
		    console.log("Stopping audio stream");

		    microphoneStream.getTracks().forEach(function(track) {
		        if (track.readyState == 'live') {
		            track.stop();
		        }
		    });

		    audioContext.close();
		    microphoneStream = null;
		    audioContext = null;
		    audioBlockIndex=0;
		  }
		}

	</script>
</body>
</html>
